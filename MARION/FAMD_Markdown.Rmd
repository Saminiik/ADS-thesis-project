---
title: "Factor Analysis for Mixed Data"
author: |
  **Author:** 
  
  | Name              | Student Number | Email Address                           |
  |:------------------|:--------------|:----------------------------------------|
  | Marion Späth     | 2772981        | m.m.spath@uu.nl                        |
date: "`r Sys.Date()`"
output:
    html_document:
      df_print: paged
      toc: true
      toc_float: yes
      number_sections: false
      highlight: haddock
---

# PCA / FAMD explanation

This notebook explores whether PCA alternatives can be used to meaningfully reduce the dimensions of our datasets (goat and cattle) before running ML models.

We have 26 variables (not counting the outcomes, wave, and ID). Of those 26 variables, only the following 6 are numeric in nature:
'age_constant', 'buy_nr_goat', 'n_previd_goat', 'number_minors', 'number_adults', 'ratio_insured_goat'.

PCA is designed for numeric data, as it calculates components that maximize the captured variance of the variables. However, the concept of variance does not apply in the same way to categorical variables, even when one-hot encoded. One alternative is Factor Analysis for Mixed Data (FAMD). It handles both numeric and categorical data. Numeric variables are treated the same way as in PCA—that is, they are standardized to have a mean of 0 and a standard deviation of 1. Categorical variables are first one-hot encoded and then weighted by their category's probability (less frequent categories receive a higher weight) to account for rarity. PCA is then applied to the resulting dataframe containing both numeric and categorical variables.

FAMD is implemented in the prince library in Python. Since we started the data manipulation in Python, I initially tried to run FAMD there as well. However, the function converts even numerical variables into dummies, which results in over 200 variables and makes interpretability and finding a reasonable number of components difficult. This is why I ran FAMD in R, where it appears to be better developed in the FactoMineR package and comes with useful visualizations. Results show that the underlying algorithm handles the mix of numeric and categorical variables well.

Still, the number of components needed to capture a substantial portion of the variance is relatively high (a minimum of 13 components is needed to capture 50% of the variance). While the results (see bar chart of variable contributions at the end of the script) suggest that some variables might be merged (e.g., all language variables), this would only minimally reduce the overall number of dimensions.

Given that we are not only interested in prediction accuracy in our ML models but also in variable contributions (which would become much more obscured with FAMD in our case), I would argue against implementing FAMD on our datasets. There are models and methods that can handle our number of variables without reducing dimensions beforehand.

# FAMD

Load libraries and data.

```{r echo=T, warning=FALSE, message=F}
# Required packages
required_packages <- c("dplyr", "tidyverse", "FactoMineR", "factoextra", "rio", "gridExtra")

# Install any missing packages, then load all
for (pkg in required_packages) { if (!requireNamespace(pkg, quietly = TRUE)) { install.packages(pkg)}
  library(pkg, character.only = TRUE)}

goat <- import("C:/Users/Marion Späth/Desktop/ADS/Thesis/Data/cattle_df.xlsx")
```

(De-) Select relevant data for FAMD. Drop outcome variable, wave, and id variables.

Then adjust classes for categorical variables.
```{r}
#goat_s <- goat %>% select(-c(cs_cs_diff_post_goat, cs_cs_ratio_post_goat, id, wave, ...1, purchase_bin, buy_goat, buy_nr_goat, ratio_insured_goat, advise_vip))

goat_s <- goat %>% select(-c(cs_cs_diff_post_cattle, cs_cs_ratio_post_cattle, id, wave, ...1, purchase_bin, buy_cattle, buy_nr_cattle, ratio_insured_cattle, advise_vip))

#numeric_columns = ['buy_nr_goat', 'n_previd_goat', 'ratio_insured_goat', 'age_constant', 'number_adults', 'number_minors']


cat_vars <- c('afm_language', 'agric_land', 'amh_language', 'educ_recoded_constant', 'eng_language', 'expend', 'irrigated_land_bin',  
              'educ_child_recoded', 'activity_child_recoded', 'household_description', 'main_info_source_recoded', 'religion_recoded', 
              'owns_phone', 'household_moved', 'why_not_purchase_recoded', 'know_vip', 'trust_vip')
goat_s[cat_vars] <- lapply(goat_s[cat_vars], as.factor)
```

Run FAMD and extract eigenvalues, and (cumulative) percentage of variance.


## 20 Dimension Solution to see overall distribution of Eigenvalues

```{r}
number_of_components = 20
res_famd <- FAMD(goat_s, ncp = number_of_components, graph = FALSE)

get_eig(res_famd)
```

Plot both Eigenvalues and Explained Variance.

```{r}
fviz_eig(res_famd, choice = c("eigenvalue"), ncp = number_of_components) #choice = c("variance", "eigenvalue")
fviz_eig(res_famd, choice = c("variance"), ncp = number_of_components)
```

Plot the contributions of the variables per dimension.

```{r}
plots <- list()
for (ncp in 1:number_of_components) {
  plots[[ncp]] <- fviz_contrib(res_famd, "var", axes = ncp)
}

# Plot 4 per page (2 rows × 2 columns)
plots_per_page <- 4
num_pages <- ceiling(length(plots) / plots_per_page)

for (i in 1:num_pages) {
  start <- (i - 1) * plots_per_page + 1
  end <- min(i * plots_per_page, length(plots))
  grid.arrange(grobs = plots[start:end], ncol = 2)
}

```


```{r}
#fviz_famd_var(res_famd, repel = T, axes = c(1,2)) # this plots two dimensions on a x and y axis
```


## 7 Dimension Solution with minimum number of dimensions

```{r}
number_of_components = 7
res_famd <- FAMD(goat_s, ncp = number_of_components, graph = FALSE)

get_eig(res_famd)
```

Plot both Eigenvalues and Explained Variance.

```{r}
fviz_eig(res_famd, choice = c("eigenvalue"), ncp = number_of_components) #choice = c("variance", "eigenvalue")
fviz_eig(res_famd, choice = c("variance"), ncp = number_of_components)
```

Plot the contributions of the variables per dimension.

```{r}
plots <- list()
for (ncp in 1:number_of_components) {
  plots[[ncp]] <- fviz_contrib(res_famd, "var", axes = ncp)
}

# Plot 4 per page (2 rows × 2 columns)
plots_per_page <- 4
num_pages <- ceiling(length(plots) / plots_per_page)

for (i in 1:num_pages) {
  start <- (i - 1) * plots_per_page + 1
  end <- min(i * plots_per_page, length(plots))
  grid.arrange(grobs = plots[start:end], ncol = 2)
}

```
