---
title: "Elastic Net"
author: |
  **Author:**  
  
  | Name              | Student Number | Email Address                         |
  |:------------------|:--------------|:---------------------------------------|
  | Marion Sp채th     | 2772981        | m.m.spath@uu.nl                        |
date: "`r Sys.Date()`"
output:
    html_document:
      df_print: paged
      toc: true
      toc_float: yes
      number_sections: false
      highlight: haddock
---

# Intro

This Markdown documents the further pre-processing of the dependent variable.

The IBLI data has been collected from households over multiple rounds. Thus, the data has a panel structure with rounds nested in households.
One modelling approach could be to simply pool the data and ignore this panel aspect. However, this could lead to data leakage and over-fitting in the machine learning models. Especially, if households do not change much over time, there will be high correlation within individuals. That means if a ML model is trained on a random subset of the data and then applied to the test subset, it will be overly confident as it was already trained on some of the same households. Similarly, the training process will be biased towards the specific households in the training set.
The result would be a model that does not truly generalise well.

To solve this issue, I will run a random effect model which will show the degree to which the households' nested structure influence the outcome estimation. Further, by extracting the residuals of this model the data has been 'cleared' of this structure and can be applied to the ML models without the risk of overfitting on individuals.

Additionally, to prepare the data for splitting, numeric variables are standardised, and categorical variable are standardised.

The data is then split into train and test datasets, respectively for goat and cattle herders. These datasets will be used to train the ML models in the other notebooks / Markdowns.


# Load Data, Libraries, Custom Functions

```{r echo=T, warning=FALSE, message=F}
set.seed(123)  # set seed for reproducibility

setwd("C:/Users/Marion Sp채th/Desktop/ADS/Thesis/")

# Required packages
required_packages <- c("dplyr", "tidyverse", "rio", "gridExtra", "ggplot2", "lme4", "caret", "glmnet")

# Install any missing packages, then load all
for (pkg in required_packages) { if (!requireNamespace(pkg, quietly = TRUE)) { install.packages(pkg)}
  library(pkg, character.only = TRUE)}

cattle <- import("C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/cattle_df_final2105.xlsx")
goat <- import("C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/goat_df_final2105.xlsx")
```


To extract the best result (or tuning parameters) of the Elastic Net.
```{r}
get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  best_result
}
```

# Prepare variables

Standardise numeric variables, factorise categorical variables.

```{r}
cattle_s <- cattle %>% select(-c( ...1, purchase_bin, advise_vip, buy_nr_cattle, n_previd_cattle, buy_cattle))
goat_s <- goat %>% select(-c( ...1, purchase_bin, advise_vip, buy_nr_goat, n_previd_goat, buy_goat))

cat_vars <- c('afm_language', 'agric_land', 'amh_language', 'eng_language', 'expend', 'irrigated_land_bin', 'activity_child_recoded', 'household_description',  'main_info_source_recoded', 'religion_recoded', 'owns_phone', 'household_moved', 'why_not_purchase_recoded', 'know_vip', 'trust_vip', 'educ_recoded_constant',  'educ_child_recoded')

num_vars <- c('age_constant', 'number_adults', 'number_minors', 'educ_child_recodedNUMERIC', 'educ_recoded_constant_num')

cattle_s[cat_vars] <- lapply(cattle_s[cat_vars], as.factor)
goat_s[cat_vars] <- lapply(goat_s[cat_vars], as.factor)

cattle_s$age_constant_z <-  as.numeric(scale(cattle_s$age_constant))
cattle_s$number_adults_z <- as.numeric(scale(cattle_s$number_adults))
cattle_s$number_minors_z <- as.numeric(scale(cattle_s$number_minors))
cattle_s$educ_child_z <- as.numeric(scale(cattle_s$educ_child_recodedNUMERIC))
cattle_s$educ_adult_z <- as.numeric(scale(cattle_s$educ_recoded_constant_num))


goat_s$age_constant_z <-  as.numeric(scale(goat_s$age_constant))
goat_s$number_adults_z <- as.numeric(scale(goat_s$number_adults))
goat_s$number_minors_z <- as.numeric(scale(goat_s$number_minors))
goat_s$educ_child_z <- as.numeric(scale(goat_s$educ_child_recodedNUMERIC))
goat_s$educ_adult_z <- as.numeric(scale(goat_s$educ_recoded_constant_num))

# take log for normal distribution of variables
cattle_s$cs_diff_log <- log(abs(cattle_s$cs_cs_diff_post_cattle)+1)
goat_s$cs_diff_log <- log(abs(goat_s$cs_cs_diff_post_goat)+1)
```

# Run RE model

The random intercept model, which includes only a random effect for individual ID to account for the panel structure of the data, shows that only 4.78% of the variance in the outcome can be attributed to differences between individuals. Thus, there is only low level of dependency. The scatterplot shows that the original outcome variable and the residuals of the RE model are almost perfectly linear. Thus, using either the extracted residuals (which have been "cleared" from the panel data structure) or the original outcome variable for subsequent models should not lead to very different results.

CATTLE:
```{r}
# Fit random intercept model
mixed_model <- lmer(cs_diff_log ~ 1 + (1 | id), data = cattle_s)

# Extract residuals (variation not explained by person-level intercepts)
cattle_s$resid_mixed <- resid(mixed_model)

hist(cattle_s$resid_mixed)

ggplot(data=cattle_s, aes(x=cs_diff_log, y=resid_mixed)) + geom_point()

summary(mixed_model)
```

### Intraclass Correlation Coefficient (ICC) Cattle

```{r}
# compute icc
icc <- 0.1416 / (0.1416 + 2.8230) *100
icc
```
Only 4.78% of the variance between individuals in the outcome can be explained. This is relatively low, indicating that the individual-level clustering likely doesn't distort the results much when not accounted for.


```{r}
# Fit random intercept model
mixed_model2 <- lmer(cs_diff_log ~ 1 + (1 | id), data = goat_s)

# Extract residuals (variation not explained by person-level intercepts)
goat_s$resid_mixed <- resid(mixed_model2)

ggplot(data=goat_s, aes(x=cs_diff_log, y=resid_mixed)) +
  geom_point()

summary(mixed_model2)
```

### Intraclass Correlation Coefficient (ICC) Cattle

```{r}
# compute icc
icc <- 0.1459 / (0.1416 + 2.0435) *100
icc
```
Only 6.68% of the variance between individuals in the outcome can be explained. Again, this is relatively low, indicating that the individual-level clustering likely doesn't distort the results much when not accounted for.



# Elastic Net

## Cattle 
Adjust variables and split into train and test set. Prepare for cross-validation.
I do this once using the original (logged) outcome and once using the residuals from the RE model to compare results.
```{r}
set.seed(123)
# original outcome
model_vars_log_cat <- cattle_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_recoded_constant", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_child_recoded",
                                     "activity_child_recoded", "household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip", "trust_vip", 
                                     "cs_diff_log"))

model_vars_log_num <- cattle_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_child_z", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_adult_z",
                                     "activity_child_recoded", "household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip", "trust_vip", 
                                     "cs_diff_log"))
# residual outcome
model_vars_res_cat <- cattle_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_adult_z", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_child_z",
                                      "activity_child_recoded","household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip",  "trust_vip", 
                                      "resid_mixed"))

model_vars_res_num <- cattle_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_child_z", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_adult_z",
                                     "activity_child_recoded", "household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip", "trust_vip",
                                      "resid_mixed"))
# log outcome
split_idx1 <- createDataPartition(model_vars_log_cat$cs_diff_log, p = 0.8, list = FALSE)
train_data1 <- model_vars_log_cat[split_idx1, ]
test_data1 <- model_vars_log_cat[-split_idx1, ]

split_idx2 <- createDataPartition(model_vars_log_num$cs_diff_log, p = 0.8, list = FALSE)
train_data2 <- model_vars_log_num[split_idx2, ]
test_data2 <- model_vars_log_num[-split_idx2, ]

# residual outcome
split_idx3 <- createDataPartition(model_vars_res_cat$resid_mixed, p = 0.8, list = FALSE)
train_data3 <- model_vars_res_cat[split_idx3, ]
test_data3 <- model_vars_res_cat[-split_idx3, ]

split_idx4 <- createDataPartition(model_vars_res_num$resid_mixed, p = 0.8, list = FALSE)
train_data4 <- model_vars_res_num[split_idx4, ]
test_data4 <- model_vars_res_num[-split_idx4, ]

#write.csv(train_data2, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/train_cattle_df.csv", row.names = FALSE)
#write.csv(test_data2, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/test_cattle_df.csv", row.names = FALSE)

# cross-validation
cv_10 = trainControl(method = "cv", number = 10)
```



Elastic net with original (logged) outcome and 10-fold CV.
```{r}
enet1 = train(cs_diff_log ~  . , 
              data = train_data1,
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet1 <- get_best_result(enet1)
best_res_enet1
best_res_enet1$model <- "Log/cat" 
# enet1$bestTune

enet2 = train(cs_diff_log ~  .,
              data = train_data2, #
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet2 <- get_best_result(enet2)
best_res_enet2$model <- "Log/num" 
best_res_enet2
```

Elastic net with residual outcome and 10-fold CV.

```{r}
enet3 = train(resid_mixed ~  .,
              data = train_data3, #
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet3 <- get_best_result(enet3)
best_res_enet3$model <- "Res/cat" 
best_res_enet3

enet4 = train(resid_mixed ~  .,
              data = train_data4, #
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet4 <- get_best_result(enet4)
best_res_enet4$model <- "Res/num" 
best_res_enet4

```


```{r}
trainings_CV_results <- bind_rows(best_res_enet1, best_res_enet2, best_res_enet3, best_res_enet4)
```


## Make and Prepare Predictions

```{r}
# Predict and assess performance
test_preds1 <- predict(enet1, newdata = test_data1)
cat("Performance on test set 1: \n")
print(postResample(pred = test_preds1, obs = test_data1$cs_diff_log))
result1 <- t(as.data.frame(postResample(pred = test_preds1, obs = test_data1$cs_diff_log)))

test_preds2 <- predict(enet2, newdata = test_data2)
cat("Performance on test 2: \n")
print(postResample(pred = test_preds2, obs = test_data2$cs_diff_log))
result2 <- t(as.data.frame(postResample(pred = test_preds2, obs = test_data2$cs_diff_log)))


test_preds3 <- predict(enet3, newdata = test_data3)
cat("Performance on test 3: \n")
print(postResample(pred = test_preds3, obs = test_data3$resid_mixed))
result3 <- t(as.data.frame(postResample(pred = test_preds3, obs = test_data3$resid_mixed)))


test_preds4 <- predict(enet4, newdata = test_data4)
cat("Performance on test 4: \n")
print(postResample(pred = test_preds4, obs = test_data4$resid_mixed))
result4 <- t(as.data.frame(postResample(pred = test_preds4, obs = test_data4$resid_mixed)))

class(result1)
PRECITION_RESULTS <- bind_rows(as.data.frame(result1), as.data.frame(result2), as.data.frame(result3), as.data.frame(result4))
```



## Goat 
Adjust variables and split into train and test set. Prepare for cross-validation.
I do this once using the original (logged) outcome and once using the residuals from the RE model to compare results.
```{r}
set.seed(123)
# original outcome
model_vars_log_cat <- goat_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_recoded_constant", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_child_recoded",
                                     "activity_child_recoded", "household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip", "trust_vip", 
                                     "cs_diff_log"))

model_vars_log_num <- goat_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_child_z", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_adult_z",
                                     "activity_child_recoded", "household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip", "trust_vip", 
                                     "cs_diff_log"))
# residual outcome
model_vars_res_cat <- goat_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_adult_z", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_child_z",
                                      "activity_child_recoded","household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip",  "trust_vip", 
                                      "resid_mixed"))

model_vars_res_num <- goat_s %>% select(c( "afm_language", "age_constant_z", "agric_land", "amh_language", "educ_child_z", 
                                      "eng_language", "expend", "irrigated_land_bin", "number_minors_z", "educ_adult_z",
                                     "activity_child_recoded", "household_description", "number_adults_z", "main_info_source_recoded", 
                                      "religion_recoded", "owns_phone", "household_moved", "why_not_purchase_recoded","know_vip", "trust_vip",
                                      "resid_mixed"))
# log outcome
split_idx1 <- createDataPartition(model_vars_log_cat$cs_diff_log, p = 0.8, list = FALSE)
train_data1 <- model_vars_log_cat[split_idx1, ]
test_data1 <- model_vars_log_cat[-split_idx1, ]

split_idx2 <- createDataPartition(model_vars_log_num$cs_diff_log, p = 0.8, list = FALSE)
train_data2 <- model_vars_log_num[split_idx2, ]
test_data2 <- model_vars_log_num[-split_idx2, ]

# residual outcome
split_idx3 <- createDataPartition(model_vars_res_cat$resid_mixed, p = 0.8, list = FALSE)
train_data3 <- model_vars_res_cat[split_idx3, ]
test_data3 <- model_vars_res_cat[-split_idx3, ]

split_idx4 <- createDataPartition(model_vars_res_num$resid_mixed, p = 0.8, list = FALSE)
train_data4 <- model_vars_res_num[split_idx4, ]
test_data4 <- model_vars_res_num[-split_idx4, ]

#write.csv(train_data2, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/train_goat_df.csv", row.names = FALSE)
#write.csv(test_data2, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/test_goat_df.csv", row.names = FALSE)

# cross-validation
cv_10 = trainControl(method = "cv", number = 10)
```



Elastic net with original (logged) outcome and 10-fold CV.
```{r}
enet1 = train(cs_diff_log ~  . , 
              data = train_data1,
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet1 <- get_best_result(enet1)
best_res_enet1
best_res_enet1$model <- "Log/cat" 
# enet1$bestTune

enet2 = train(cs_diff_log ~  .,
              data = train_data2, #
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet2 <- get_best_result(enet2)
best_res_enet2$model <- "Log/num" 
best_res_enet2
```

Elastic net with residual outcome and 10-fold CV.

```{r}
enet3 = train(resid_mixed ~  .,
              data = train_data3, 
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet3 <- get_best_result(enet3)
best_res_enet3$model <- "Res/cat" 
best_res_enet3

enet4 = train(resid_mixed ~  .,
              data = train_data4, 
              method = "glmnet",
              trControl = cv_10,
              tuneLength = 10)
best_res_enet4 <- get_best_result(enet4)
best_res_enet4$model <- "Res/num" 
best_res_enet4

```


```{r}
trainings_CV_results <- bind_rows(best_res_enet1, best_res_enet2, best_res_enet3, best_res_enet4)
trainings_CV_results
```


## Make and Prepare Predictions

```{r}
# Predict and assess performance
test_preds1 <- predict(enet1, newdata = test_data1)
cat("Performance on test set 1: \n")
print(postResample(pred = test_preds1, obs = test_data1$cs_diff_log))
result1 <- t(as.data.frame(postResample(pred = test_preds1, obs = test_data1$cs_diff_log)))

test_preds2 <- predict(enet2, newdata = test_data2)
cat("Performance on test 2: \n")
print(postResample(pred = test_preds2, obs = test_data2$cs_diff_log))
result2 <- t(as.data.frame(postResample(pred = test_preds2, obs = test_data2$cs_diff_log)))


test_preds3 <- predict(enet3, newdata = test_data3)
cat("Performance on test 3: \n")
print(postResample(pred = test_preds3, obs = test_data3$resid_mixed))
result3 <- t(as.data.frame(postResample(pred = test_preds3, obs = test_data3$resid_mixed)))


test_preds4 <- predict(enet4, newdata = test_data4)
cat("Performance on test 4: \n")
print(postResample(pred = test_preds4, obs = test_data4$resid_mixed))
result4 <- t(as.data.frame(postResample(pred = test_preds4, obs = test_data4$resid_mixed)))

class(result1)
PRECITION_RESULTS <- bind_rows(as.data.frame(result1), as.data.frame(result2), as.data.frame(result3), as.data.frame(result4), .id = "model_id")
rownames(PRECITION_RESULTS) <- NULL
PRECITION_RESULTS$model_id[PRECITION_RESULTS$model_id == 1] <- "log outcome / categorical education"
PRECITION_RESULTS$model_id[PRECITION_RESULTS$model_id == 2] <- "log outcome / numeric education"
PRECITION_RESULTS$model_id[PRECITION_RESULTS$model_id == 3] <- "log residual outcome / categorical education"
PRECITION_RESULTS$model_id[PRECITION_RESULTS$model_id == 4] <- "log residual outcome / numeric education"
PRECITION_RESULTS



```


```{r}
#set.seed(123)
#split_idx_goat <- createDataPartition(goat_s$resid_mixed, p = 0.8, list = FALSE)
#train_data_goat <- goat_s[split_idx_goat, ]
#test_data_goat <- goat_s[-split_idx_goat, ]
# 
# split_idx_cattle <- createDataPartition(cattle_s$resid_mixed, p = 0.8, list = FALSE)
# train_data_cattle <- cattle_s[split_idx_cattle, ]
# test_data_cattle <- cattle_s[-split_idx_cattle, ]
# 
#write.csv(train_data_goat, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/train_goat_df.csv", row.names = FALSE)
#write.csv(test_data_goat, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/test_goat_df.csv", row.names = FALSE)
# 
# write.csv(train_data_cattle, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/train_cattle_df.csv", row.names = FALSE)
# write.csv(test_data_cattle, "C:/Users/Marion Sp채th/Desktop/ADS/Thesis/Data/test_cattle_df.csv", row.names = FALSE)
```